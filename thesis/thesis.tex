%% Thesis template conforming to Williams College rules.
% Thanks to Ben Wood '08 and other contributors.
%
\documentclass[twoside]{report}

\usepackage[top=1.0in, bottom=1in, left=1.5in, right=1in, includehead]{geometry}
\pagestyle{headings}
\usepackage{setspace}

%% Special math fonts and symbols
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amsthm}

%% Rotate tables and figures
\usepackage{rotating}

%% Used for TODO items
\usepackage{color}

%% used for code listings.
\usepackage{float}

%% Used to replace LaTeX's ugly emptyset with diameter, which looks nicer.
\usepackage{wasysym}

%% Nicely formatted algorithms.
\usepackage{algorithmicx}
\usepackage[chapter]{algorithm}
\usepackage{algpseudocode}

%% Nicely formatted listings.
\usepackage{listings}

%% More kinds of arrow with stuff
\usepackage{empheq}\usepackage{multicol}
\usepackage{subfigure}

%% urls
\usepackage{hyperref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Thesis body %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Title page              %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{titlepage}
  $\;$
  \vskip1.5in
  \onehalfspacing
  \begin{center}
    {\LARGE
      Distributed Reliable Easy Shell
    }
    \large
    \vskip.25in
    by\\
    Markus Feng\\
    \vskip.125inProfessor Daniel W. Barowy, Advisor\\
    \vskip.125inProfessor Jeannie Albrecht, Advisor\\
    \singlespacing\vskip.375in
    \small
    A thesis submitted in partial fulfillment\\
    of the requirements for the\\
    Degree of Bachelor of Arts with Honors\\
    in Computer Science\\
    \vskip.5in
    Williams College\\
    Williamstown, Massachusetts\\
    \vskip.5in
    \today
    %%\vskip.5in
    %%{\Huge \textbf{DRAFT}}
  \end{center}
\end{titlepage}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\tableofcontents
\listoffigures
\listoftables
\onehalfspacing

\chapter*{Abstract}

Performing tasks that are distributed among many systems currently fail to achieve each of the goals of being reliable, easy to set up, closely resembling an existing technology, and friendly to users without distributed systems knowledge.
Because distributed systems are inherently unreliable, succeeding in these goals require the system to provide an abstraction for error handling and recovery that account for the many failure cases that may arise.
This thesis project attempts to define a set of error handling semantics that is simple to use, but powerful enough to be applied to a diverse set of use cases.
The project will also involve implementing a shell-based programming language, Dresh (standing for Distributed Reliable Easy shell), to demonstrate the usefulness of the error handling semantics as defined.
Using this language, anyone with basic shell knowledge should be able to write and run scripts that runs over multiple machines reliably.
This will greatly aid in increasing the accessibility and simplifying the process of running distributed programs in domains including systems administration and scientific computing.


\chapter*{Acknowledgments}

I could not have written this thesis without the help of my advisors, Dan Barowy and Jeannie Albrecht, who have both been invaluable in guiding me along in the process. Special thanks to both Dan and Jeannie for taking me on as a thesis student during their sabbadical leaves, during a difficult time in the world, as we work through the COVID-19 pandemic in all facets of our lives.

% TODO expand

%%%%%%%% Chapters %%%%%%%%%%%%

%% Introduction
\chapter{Introduction}
\begin{itemize}
  \item What my project is
  \item What I've done
  \item How I've done it
  \item Measurement of success
\end{itemize}

\section{Motivation}
\begin{itemize}
  \item What makes this project unique (will elaborate in background)
  \item Introduce three pillars (distributed, reliable, easy to use)
\end{itemize}

\subsection{Distributed}
\begin{itemize}
  \item Why would someone want a distributed program?
  \item What are some challenges of a distributed program?
  \item Talk about error handling, segue into reliability
\end{itemize}

\subsection{Reliable}
\begin{itemize}
  \item Error handling
  \item Why is reliability important?
  \item Segue - how does it tie into being easy to use
\end{itemize}

\subsection{Easy to use}
\begin{itemize}
  \item Ease of use
  \item Ad-hoc
  \item Low knowledge barrier
  \item Why is being easy to use important?
  \item Distinguishes Shard from other projects
\end{itemize}

\section{Summary}
\begin{itemize}
  \item Explain the layout of the rest of my thesis
\end{itemize}


%% Background
\chapter{Background}

This thesis describes a set of error handling semantics for a distributed command-line shell, along with Dresh, an implementation of a distributed shell with those semantics.
This chapter starts with describing the background behind command-line shells, focusing in particular on their relationship with the UNIX operating system and the specification of the POSIX shell.
After that, this chapter moves on providing an overview of distributed computing, with a deeper look at their fault tolerance properties that will guide the error handling semantics in this thesis, and several examples of distributed systems, including Hadoop, Ganglia, and Plush.
Next, this chapter will talk about existing examples of distributed command line shells, including their features, implementations, and weaknesses.
Finally, this chapter closes out with a summary of existing shells, distributed systems, and distributed shells, along with how the Dresh shell builds upon these existing systems.

\section{Command-line Shells}
\subsection{UNIX Shell}
UNIX is an operating system designed at Bell Labs, with the first versions appearing around 1969-1970 \cite{10.1145/361011.361061}.
UNIX was an influence in many operating systems in use today, with its original form evolving into various BSD distributions (NetBSD, FreeBSD, OpenBSD), and the GNU operating system, which is the basis of Linux distributions today, was designed to be UNIX compatible \cite{bretthauer2001open}.

One of the standard ways of interacting with the UNIX operating system is through a command-line shell \cite{10.1145/361011.361061}.
The operation of the shell involves reading in lines of text typed by the user, and performing a command based on the input text.
The most basic command consists of a space-separated list of strings, with the first string being the name of the command, and the remaining strings being the arguments for the command.
The shell searches the file system for the appropriate program to run, based on the name of the command, and feeds the arguments as input to the program.
By default, the standard output of the program is displayed back to the user by the visual interface of the shell program, but indirections can modify this by transferring the output to a file or another program.
When execution completes, control is given back to the user, who can run another command line command on the shell.
Because the command line is a program itself, the shell can run itself as a program with the input being a file containing shell commands.
The command-line shell is useful in a wide variety of contexts, in being one of the easiest ways to programmatically interface with the operating system itself, and many operations on computers are able to be performed or even require using shell \cite{10.1145/3371111}.

\subsection{POSIX Shell}
POSIX is a family of IEEE standards originating in the early 1980s that specify a portable operating system interface based on UNIX \cite{10.1145/210308.210315}.
Contained within the POSIX specification is a specification of the POSIX shell, which describes the interface that the shell command language should conform to \cite{posix2017}.
Because each operating system that conform to the POSIX interface must implement a POSIX shell, there have been a wide variety implementations of POSIX shells on numerous platforms, many of which have additional features that extend the capabilities of the shell.
The POSIX shell is popular across computing platforms, including even platforms that are not designed to be POSIX compatible, though notably a majority of POSIX shells do not fully conform to the POSIX specification \cite{10.1145/3371111}.

\section{Distributed Computing}

A distributed computing system, or a distributed system, is a computer system that consists of multiple processors one one or more machines that work together but do not directly share memory \cite{10.1145/72551.72552}.
This thesis in particular focuses on multicomputer distributed systems that communicate over a network that is not guaranteed to be reliable. 
As such, there may be errors or faults that occur during the operation of the system.

\subsection{Fault Tolerance in Distributed Systems}
There has been significant work in the field of fault tolerant distributed systems, as one important goal in computer systems is to be dependable, which comes with significant challenges when in a distributed environment, compared to a program running a single process or machine \cite{10.1145/311531.311532}.

% Safety/Liveliness
The two classes of fault tolertance properties in distributed programs are properties of safety and liveliness \cite{1702415}.
Safety properties ensure that the state of the distributed system must not be some state, while liveliness properties ensure that the state of the distributed system must eventually be in some state.
For example, a safety property of a distributed system may be that one part of a distributed program is not executed until a different part is complete, while a liveliness property of a distributed system may be that the program eventually provides a result, even if one or more machines are stuck in a loop during execution.

% Masking/Fail-safe/Nonmasking
When designating a system to be fault tolerant, it is important to specify which types of faults that the system is tolerant against, and what types of fault tolerant properties are satisfied by the system \cite{10.1145/311531.311532}.
In the strongest form, a system with masking fault tolerence is able to satisfy both safety and liveliness properties against a given set of faults.
Slightly weaker is fail-safe fault tolerance, which ensures safety but does not make liveliness guarantees, capturing the notion that certain illegal states will never appear.
Safety is important in many situations, such as making sure that a missile does not launch in case of individual component failures.
On the other hand, nonmasking fault tolerence, which ensures liveliness but does not make safety guarantees, captures the notion of a system always making progress towards completion, despite the possibility of some amount of incorrect behavior with the program.
Traditionally less focus has been placed on systems in ensuring liveliness compared to ensuring safety, as liveliness issues can be resolved in many cases by manually stopping the system, whereas safety issues can lead to large amounts of damage.

% Potential sections:
% Crash/Fail-stop/Byzantine
% Redundancy
% Error detection and correction

\subsection{Examples}
Fault tolerant distributed systems exist in many forms, with widespread practical usage.
Typically, these systems target solving a specific type of distributed problem, with differences based on the priorities and goals of the individual system.

\subsubsection{MapReduce/Hadoop}
MapReduce is a distributed computation framework developed by Google to handle and process large amounts of data \cite{dean2004mapreduce}.
The data processing is done by splitting up the input into key-value pairs, applying a function in a distributed fashion on each of those value pairs, using a reduce function to combine the pairs that share a key.
In the implementation used by Google in 2004, a typical MapReduce cluster can contain hundreds or thousands of machines.
The problem of making data available to other machines is solved through the use of a distributed file system formed by the disks located at each of the machines in the cluster, which partitions the data storage to individual machines.
Because the data is stored on a particular machine, that same machine can be in charge of performing the necessary map and reduce computations.

Apache Hadoop is an open source distributed programming framework that can be used to run MapReduce-style computation on large datasets \cite{Hadoop}.
Hadoop is designed to target the use case of data processing with extremely large data sets that cannot be handled with ordinary programming techniques that depend on all of the data to be available on one machine and the work being done on a single process.
Hadoop uses a distributed filesystem in a similar manner to Google's MapReduce implementation, with explicit goals of being able to handle faults such as hardware failure, using techniques including replication to make sure that the data is stored reliably across the cluster \cite{borthakur2007hadoop}.
The fault tolerant properties of Hadoop makes it useful in production usage, where errors are to be expected to occur when dealing with large clusters of machines.

\subsubsection{Ganglia/GEXEC}
Ganglia is a monitoring system for scalable high-performance distributed programs \cite{MASSIE2004817}.
One of the central goals of Ganglia is robustness.
Ganglia is designed to monitor failures and continue to operate in the presence of these failures, as individual failures are common in large-scale systems with high resource demands and utilization.
Types of failures as identified by Ganglia include computational, I/O, and network failures on individual machines, along with bottlenecks on a larger scale.

As a monitoring system, it is possible to use the information provided by Ganglia in an application or an application framework.
The utility GEXEC allows executing jobs of machines on a cluster, while providing data and signal forwarding on jobs between the machines \cite{gexec}.
GEXEC supports a mode of operation that utilizes Ganglia, which takes advantage of Ganglia's failure monitoring and handling features to ensure that the system is robust even on large distributed clusters.

\subsubsection{Plush}
Plush is a unified framework for managing various classes of programs to be executed in a wide variety of distributed environments \cite{10.5555/1349426.1349441}.
Like the other distributed system frameworks mentioned above, Plush has an emphasis on detection and recovery from failures through monitoring the state of the system.
Plush acts as a platform for building applications on, providing a set of abstractions and configurations to allow error recovery in a user-specified manner, designed in a fashion to be applicable to a wide range of different types of distributed programs.

\section{Distributed Command-line Shells}
The concept of command-line shells and distributed computing can be combined to form a distributed command-line shell.
A distributed shell is a shell that supports command-line shell features over a distributed cluster of machines.

\subsection{Examples}
The concept of distributed shells has been visited in the past in various forms.
However, none of these shells fully realize the goals of the Dresh shell.
In particular, unlike for many of the distributed systems mentioned above, the issue of distributed error handling and recovery is not well addressed by any of the solutions below.

\subsubsection{SSH}
One method of making an ad-hoc distributed shell is to invoke the SSH secure shell utility multiple times.
The SSH utility allows users to connect to remote machines over TCP and access the command line shell on those machines \cite{rfc4251}.
Given a command to run and a list of remote hosts, the shell can iterate over the list, invoke SSH with that remote host as an argument, run the command on the remote host, and finally collect the results back on the local machine.
Notably, this method is that it does not handle error recovery well, or guarantee reliable execution in the event of failures.

\subsubsection{DSH (Dancer's Shell)}
The DSH (Dancer's Shell) Unix program allows the user to send a shell command to all machines in a cluster defined by the user \cite{dshdancer}.
DSH uses an underlying remote execution protocol, such as SSH, for executing shell programs on remote hosts.
The command invocation occurs in a hierarchial fashion, with each node sending the command to some amount of child nodes until the program is executed on all nodes in the cluster.
Notably, for the DSH program, there does not exist an emphasis of reliable execution and error recovery from failures that may arise from the distributed nature of the program.
Other similar implementations of the DSH program exist in various forms, some of them implemented with a different language or work on different platforms.

\subsubsection{Distsh}
Distsh (Distributed Command Line Interface) is an implementation of a generic distributed shell environment, with steps taken to make accessing a remote machine just like accessing a local one \cite{distsh}.
The Distsh shell language only specifies semantics for connecting to a single remote machine at a time, rather than having the unit remote machine being a cluster as is the case in DSH.
Similar to DSH, there does not exist error handling semantics to allow reliable execution and error recovery.
The paper specifies that the implementation currently only works when the machine to access is localhost, and there does not appear to have been visible progress on the project since the paper was made public.

\section{Summary}
Command-line shells are an important and useful interface for interacting with a computer.
Therefore, it makes sense to be able to use the command-line shell to interact with many computers simultaneously in a distributed manner.
However, distributed systems come with existing challenges, particularly because failures are much more likely when there are more avenues of failure and more machines that can fail.
While many existing distributed systems have built-in error handling and recovery mechanims, prior solutions for extending the shell to a cluster of distributed systems do not sufficiently take into account these same errors.
This thesis aims improve upon existing solutions by unifying the reliability built in to distributed systems with simplicity and ease of use of the command-line shell interface.

\chapter{Design}

\begin{itemize}
  \item High level design
  \begin{itemize}
    \item Satisfying the three pillars (ease of use, distributed, reliable)
    \item Use language to solve problem
  \end{itemize}
\end{itemize}

\section{Application classes}

\begin{itemize}
  \item Solves the problem of: reliability/error handling semantics
  \item Overall error model (or maybe keep it specific to the application classes)
  \item Describe the existing application classes
\end{itemize}

\subsection{Application class: \texttt{single\_command}}

\begin{itemize}
  \item Application features 
  \item Error handling
  \item Give example of when to use
\end{itemize}

\subsection{Application class: \texttt{data\_parallel}}

\section{Language design}

\begin{itemize}
  \item Solves the problem of: ease of use/familiarity
  \item Describe the programming language
  \item Based on the POSIX shell standard
  \item Simple new syntax/semantics for distributed work
  \begin{itemize}
    \item Cluster management (builtin)
    \item Application classes/error handling semantics support
    \item Run on remote host (@@) 
  \end{itemize}
\end{itemize}

\subsection{Example programs}

\begin{itemize}
  \item Give examples and explain in detail
  \item Example program: Hello world
  \item Example program: Memory usage in cluster
  \item Example program: Word count in large file
\end{itemize}

\section{Protocol design}

\begin{itemize}
  \item Solves the problem of: distributed
  \item Describe the distributed protocol
  \item Note that this is about the design of the protocol, rather than the implementation details
\end{itemize}

\chapter{Implementation}

\section{Architecture}

\begin{itemize}
  \item Split up into 4 parts: Shell, language, protocol, application class
  \item Basic summary of each part, its purpose, and how they connect together
\end{itemize}

\section{Shell implementation}

\begin{itemize}
  \item In depth writing about how the shell is implemented
  \item OCaml, directly on top of Unix primitives (rather than on an existing shell)
  \item Invokable with command line
  \item Interactive and non-interactive mode
  \item Most features are written to work locally, and separated so that language/protocol/application class implementations are abstracted
\end{itemize}

\section{Language implementation}

\begin{itemize}
  \item Implemented by referring to POSIX shell specification
  \item Parse: Use recursive parser combinator library Angstrom
  \item Interpret: Interpret parsed objects in functions directly, with support for custom features needed by Shard
  \item Some specification features are not yet supported, but there is no reason why support cannot be added if needed
\end{itemize}

\section{Protocol implementation}

\begin{itemize}
  \item Model: copy executable to each remote machine, then use SSH to communicate between machines
  \item Support SSH config
  \item Each remote invocation spawns two processes locally and two processes remotely: justified by easy to separate remote invocations
  \item Use OCaml Async RPC for interprocess communication between processes on the same machine: strongly typed, serialization supported, etc
  \item Heavyweight but works well for ad-hoc programming
\end{itemize}

\section{Application class implementation}

\begin{itemize}
  \item Each application class implementation conforms to a specific interface
  \item Handles how new jobs are dispatched, how existing jobs are managed, retry, error handling, etc. as needed by the application class
  \item Ability to plug in support for new application classes
\end{itemize}

\section{Implementation trade-offs}

\subsection{Performance}
\begin{itemize}
  \item Quantify performance tradeoffs? examples, stats, graphs, etc
\end{itemize}

\subsection{Alternative Approaches}
\begin{itemize}
  \item Other languages
  \item Threads vs processes
\end{itemize}

\chapter{Evaluation}

\section{Distributed}
\begin{itemize}
  \item Can be run over network
  \item Graph to show running time for X machines in cluster (use CS machines? rent some VMs?)
\end{itemize}

\section{Reliable}

\begin{itemize}
  \item Still works even in error conditions
  \item Graph completion time vs random failure rate for \texttt{single\_command} programs with intermittent network errors
  \item Graph completion time vs random failure rate for \texttt{data\_parallel} programs with both temporarily and permanently failing hosts
\end{itemize}

\section{Easy to use}

\begin{itemize}
  \item Provide examples of sample programs
  \item If time permits, ask other programmers (potentially with less knowledge on distributed systems/programming languages) to try writing programs
  \item Line of code/code size comparisons?
\end{itemize}

\chapter{Conclusion}
\begin{itemize}
  \item Research question
  \item Solution (design, implementation)
  \item Measuring success (three pillars)
  \item Future work
  \item What did this thesis accomplish?
\end{itemize}

%%%%%%%% References %%%%%%%%%%
\bibliographystyle{acm}
\bibliography{references}
%%%%%%%% End References %%%%%%

\end{document}
